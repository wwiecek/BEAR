
# Benchmarks of Experimental Accuracy in Research

![](doc/bear_banner.png)

# Sources of data in this project

Up-to-date document with short descriptions is 
[available as a Google Doc](https://docs.google.com/document/d/1ZZAEwfHS0aAELN1w1lqEO6-eeu31_WdL/edit?usp=sharing&ouid=114240127695432531696&rtpof=true&sd=true).

General methodology for creating sets of z-values:

- Characterise the method used to obtain the estimates:
    - `RCT` is the main category we care about (available in Adda et al, Cochrane database, Askarov, Brodeur)
    - in Jager and Leek there is no classification done by the authors, but we can look for keywords "randomised", "randomized" and "controlled" in study titles to categorise them as RCTs
    - `mixed` category in Askarov et al means "experimental and observational"
    - `observational` means non-RCT in Cochrane
    - we have a few instrumental variable and differences-in-differences estimates from Brodeur et al
    - all other datasets mix various types of effects and are therefore `NA` 
- Extract or calculate `z`:
    - `z = b/se` in most datasets 
    - if no SE is avaialble, but we have p-value, we do `-qnorm(p/2)` (or `sign(b)*qnorm(1-p/2)` to retrieve sign of z)
    - for Barnett and Wren there are no SE but we have 95% intervals; we switch to log scale, calculate `se` by dividing by 3.96 and `b` as midpoint
    - for Sladekova et al we use Fisher's z transformation of correlation coefficients, `b = 0.5*log((1 + yi)/(1 - yi))`
    - for MetaPsy database it is standardised to Hedges' $g$
- If some `z` values were truncated in some way, keep an indicator for that (Jager and Leek only)
- Extract year
    - if available, year of intervention (Askarov et al); if not, year of study; 
    - in one case (Yang et al) I retrieve year of study it from study titles, since half of them have dates available
- Keep study indicator, labelled `studyid`
- For sets of meta-analyses, also retain `metaid` indicator
- Remove studies where z's are NA before saving (to reduce size of data)
- Join into a single table with column `dataset` 



Post-processing:

- Truncate very large z values ourselves 
- Add number of observations in each study, 
- Add number of studies in each meta-analysis 
- For large datasets, choose one z-value per study
- Add study weights as 1 / (N values reported in that study)


```{r echo=FALSE, messages=FALSE}
library(dplyr)
source("R/settings.R")
bear <- readRDS("data/BEAR.rds")
bear %>% 
  group_by(dataset) %>% 
  summarise(n_z = n(), 
            n_meta = n_distinct(metaid), 
            median_j  = median(j),
            n_study = n_distinct(studyid), 
            median_k = median(k), 
            pct_signif = sum(abs(z)>1.96)/n(),
            type = {
              tab <- table(method)
              counts <- c(tab)
              na_count <- sum(is.na(method))
              if (na_count > 0) counts <- c(counts, `NA` = na_count)
              paste(paste0(names(counts), ": ", counts), collapse = ", ")
            }
  ) %>% mutate(dataset = bear_names[dataset])
```
