
# Benchmarks of Empirical Accuracy in Research

BEAR is a "meta"-database containing z values, effect sizes and standard errors 
from existing databases in various scientific disciplines. 
It doesn't contribute any new data, but 
repackages and merges what's publicly available in a manner which we hope 
is maximally user-friendly. Our intention is to help researchers interested in 
issues of replication, exchangeability, meta-analysis etc. etc.

![](doc/bear_banner.png)

# Datasets included in BEAR

References, details of data availability and processing, links to raw data, and short descriptions of each dataset are in [a separate PDF in the main folder](datasets.pdf). Main data processing script is [process_data.md](process_data.md) and 

Here is a short summary of what's included in BEAR:

```{r echo=FALSE, messages=FALSE}
library(dplyr)
source("R/settings.R")
bear <- readRDS("data/BEAR.rds")
bear_summary <- bear %>% 
  group_by(dataset) %>% 
  summarise(n_z = n(), 
            n_meta = n_distinct(metaid), 
            n_study = n_distinct(studyid), 
            mean_k  = n()/n_distinct(studyid), 
            pct_signif = sum(abs(z)>1.96)/n()
            # type = {
            #   tab <- table(method)
            #   counts <- c(tab)
            #   na_count <- sum(is.na(method))
            #   if (na_count > 0) counts <- c(counts, `NA` = na_count)
            #   paste(paste0(names(counts), ": ", counts), collapse = ", ")
            # }
  ) %>% 
  mutate(domain = bear_domain[dataset])

bear_summary %>% 
  arrange(dataset) %>% 
  relocate(domain, .after = dataset) %>% 
  mutate(dataset = bear_names[dataset]) %>% 
  rename(n_values = n_z)
```

Datasets fall into four main categories that will be useful for different types of metascientific investigations: curated datasets of single studies, curated sets of meta-analyses (i.e. with additional `metaid` grouping column), large-scale scraped datasets from PubMed/Medline, and replication datasets. Additional groupings are available in some datasets.

```{r echo=FALSE, messages=FALSE}
bear_summary %>% 
  mutate(gr = bear_classification[dataset]) %>% 
  # mutate(gr = ifelse(gr == "meta", "curated", gr)) %>% 
  group_by(gr) %>% 
  summarise(n_datasets = n(),
            n_study = sum(n_study),
            n_meta = ifelse(sum(n_meta) == n_datasets, NA, sum(n_meta)),
            n_values = sum(n_z),
            pct_signif = sum(pct_signif*n_z) / sum(n_z))
```


# Modelling datasets using mixture models

## Optional post-processing 

To fit mixture models described in the accompanying paper, we do minimal postprocess (`postprocess.R`):

- Add number of observations in each study and number of studies in each meta-analysis 
- Add study weights as 1 / (N values reported in that study)
- For large datasets (>50,000 rows), choose one z-value per study
- Truncate very large z values (z > 20) and replace "z = 0" statements with "z < 0.5" (z=0 would not work when fitting mixtures)

In `fit_mixtures.R` we create a fit for each of the datasets, saved in `mixtures/`. This can take a few minutes per dataset.

We calculate summaries for each dataset (e.g. probablity of significance, replication, correct sign) in `calculate_psr.R`



